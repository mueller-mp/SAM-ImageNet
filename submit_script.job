#!/bin/bash
#SBATCH --ntasks=1                # Number of tasks (see below)
#SBATCH --cpus-per-task=12       # Number of CPU cores per task
#SBATCH --nodes=1                 # Ensure that all cores are on one machine
#SBATCH --time=5-23:59            # Runtime in D-HH:MM
#SBATCH --gres=gpu:8    # optionally type and number of gpus
# #SBATCH --mem=50G                # Memory pool for all cores (see also --mem-per-cpu)
#SBATCH --mem-per-gpu=32G
#SBATCH --output=/mnt/qb/work/hein/mmueller67/logs/hostname_%j.out  # File to which STDOUT will be written - make sure this is not on $HOME
#SBATCH --error=/mnt/qb/work/hein/mmueller67/logs/hostname_%j.err   # File to which STDERR will be written - make sure this is not on $HOME
#SBATCH --mail-type=END           # Type of email notification- BEGIN,END,FAIL,ALL
#SBATCH --mail-user=maximilian.mueller@wsii.uni-tuebingen.de   # Email to which notifications will be sent
#SBATCH --constraint=ImageNet2012
scontrol show job $SLURM_JOB_ID
#python3 -m torch.distributed.launch --nproc_per_node=8 train.py /scratch_local/datasets/ImageNet2012 --model resnet101 --weight_dropout 0.4 --opt_dropout 0.5 --nograd_cutoff 0.02 --temperature 300 --epochs 90 --batch-size 64 --lr 0.2 --sched cosine --weight-decay 1e-4 --smoothing 0.0 --model-ema --sam_variant=sam --experiment rn101 --rho 0.001 --isASAM --elementwise --elementwise_linf  

# python3 -m torch.distributed.launch --nproc_per_node=8 train.py /scratch_local/datasets/ImageNet2012 --model resnet50 --epochs 90 --batch-size 64 --lr 0.2 --sched cosine --weight-decay 1e-4 --smoothing 0.0 --model-ema --sam_variant=sam --experiment elementwiseLinf  --rho 0.005 --isASAM --elementwise_linf

python3 -m torch.distributed.launch --nproc_per_node=8 train.py /scratch_local/datasets/ImageNet2012 --model vit_small_patch16_224 --epochs 90 --batch-size 64 --lr 0.2 --sched cosine --weight-decay 1e-4 --smoothing 0.0 --model-ema --sam_variant=sam --experiment vit_new --rho 0.01 --isASAM  --layerwise 

#python3 -m torch.distributed.launch --nproc_per_node=8 train.py /scratch_local/datasets/ImageNet2012 --model vit_small_patch16_224 --epochs 90 --batch-size 64 --lr 0.2 --sched cosine --weight-decay 1e-4 --smoothing 0.1 --model-ema --sam_variant=base --experiment vit_new --rho 0.05 --isASAM --elementwise_linf --only_bn  

# python3 -m torch.distributed.launch --nproc_per_node=8 train.py /scratch_local/datasets/ImageNet2012 --model vit_small_patch16_224 --epochs 90 --batch-size 64 --lr 0.2 --sched cosine --weight-decay 0.3 --model-ema --sam_variant=sam --rho 0.2 --experiment vit_new --clip-grad 2. --opt adamw --drop 0.1 

# python3 validate_folder.py /scratch_local/datasets/ImageNet2012 --model resnet50 --batch-size 64 --folder ./output/train/elementwiseLinf --num-gpu 8 --filter last

# python3 validate_folder.py /scratch_local/datasets/ImageNet2012 --model resnet101 --batch-size 64 --folder ./output/train/rn101 --num-gpu 8 --filter last
